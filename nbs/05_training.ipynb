{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "> Pytorch lightning modules for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import Any, Type\n",
    "\n",
    "import lightning as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchmetrics.regression.mae import MeanAbsoluteError\n",
    "from torchmetrics.regression.mse import MeanSquaredError\n",
    "from torchvision.models.efficientnet import (EfficientNet_B0_Weights,\n",
    "                                             efficientnet_b0)\n",
    "\n",
    "from neuralresonator.dsp import biquad_freqz\n",
    "from neuralresonator.utilities import plot_sample, FFTLoss\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class MultiShapeMultiMaterialLitModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        optimizer: Type[optim.Optimizer],\n",
    "        scheduler: Type[optim.lr_scheduler.LRScheduler],\n",
    "        criterion: nn.Module = FFTLoss(),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.encoder = efficientnet_b0(\n",
    "            weights=EfficientNet_B0_Weights.DEFAULT,\n",
    "        )\n",
    "\n",
    "        self.mse = MeanSquaredError()\n",
    "        self.mae = MeanAbsoluteError()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def step(self, batch: Any):\n",
    "        mask = batch[\"mask\"]\n",
    "        coords = batch[\"coords\"]\n",
    "        audio = batch[\"audio\"]\n",
    "        material_params = batch[\"material_params\"]\n",
    "\n",
    "        mag_ffts = torch.fft.rfft(\n",
    "            audio.float().clamp(-1, 1),\n",
    "        ).abs()\n",
    "\n",
    "        # Repeat mask to match weights\n",
    "        features = self.encoder(mask.repeat(1, 3, 1, 1).float())\n",
    "\n",
    "        # Predict biquad coefficients\n",
    "        ba = self.forward(torch.cat([features, coords, material_params], dim=-1))\n",
    "        b = ba[..., :3]\n",
    "        a = ba[..., 3:]\n",
    "\n",
    "        p_mag_ffts = biquad_freqz(b, a, audio.shape[-1]).prod(dim=-2).sum(dim=-2).abs()\n",
    "\n",
    "        loss = self.criterion(\n",
    "            p_mag_ffts,\n",
    "            mag_ffts,\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            loss=loss,\n",
    "            a=a,\n",
    "            b=b,\n",
    "            p_mag_ffts=p_mag_ffts,\n",
    "            mag_ffts=mag_ffts,\n",
    "            audio=audio,\n",
    "        )\n",
    "\n",
    "    def get_first_and_plot(\n",
    "        self,\n",
    "        batch: Any,\n",
    "        name: str,\n",
    "    ) -> None:\n",
    "        with torch.no_grad():\n",
    "            # Get the first sample from the batch\n",
    "            a = batch[\"a\"][0].cpu().numpy()\n",
    "            b = batch[\"b\"][0].cpu().numpy()\n",
    "            audio = batch[\"audio\"][0].cpu().numpy()\n",
    "            fig, pred_signal = plot_sample(\n",
    "                a=a,\n",
    "                b=b,\n",
    "                gt_audio=audio,\n",
    "            )\n",
    "            wandb.log({f\"{name}/plot\": wandb.Image(fig)})\n",
    "            wandb_gt_audio = wandb.Audio(audio, sample_rate=32000)\n",
    "            wandb_pred_audio = wandb.Audio(pred_signal, sample_rate=32000)\n",
    "            wandb.log({f\"{name}/audio\": [wandb_gt_audio, wandb_pred_audio]})\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: Any,\n",
    "        batch_idx: int,\n",
    "    ):\n",
    "        batch_output: dict = self.step(batch)\n",
    "        self.log(\"train/loss\", batch_output[\"loss\"], on_step=True, on_epoch=False)\n",
    "        if batch_idx % self.trainer.val_check_interval == 0 and self.logger:\n",
    "            self.get_first_and_plot(\n",
    "                batch=batch_output,\n",
    "                name=\"train_epoch_end\",\n",
    "            )\n",
    "\n",
    "        return batch_output[\"loss\"]\n",
    "\n",
    "    def validation_step(\n",
    "        self,\n",
    "        batch: Any,\n",
    "        batch_idx: int,\n",
    "    ):\n",
    "        batch_output: dict = self.step(batch)\n",
    "        self.log(\"val/loss\", batch_output[\"loss\"])\n",
    "        return None\n",
    "\n",
    "    def test_step(\n",
    "        self,\n",
    "        batch: Any,\n",
    "        batch_idx: int,\n",
    "    ):\n",
    "        batch_output: dict = self.step(batch)\n",
    "\n",
    "        p_mag_ffts = batch_output[\"p_mag_ffts\"]\n",
    "        mag_ffts = batch_output[\"mag_ffts\"]\n",
    "\n",
    "        self.mae(torch.log(p_mag_ffts + 1e-10), torch.log(mag_ffts + 1e-10))\n",
    "        self.mse(torch.log(p_mag_ffts + 1e-10), torch.log(mag_ffts + 1e-10))\n",
    "        return None\n",
    "\n",
    "    def on_test_epoch_end(\n",
    "        self,\n",
    "    ):\n",
    "        self.log(\"test/mae\", self.mae.compute())\n",
    "        self.log(\"test/mse\", self.mse.compute())\n",
    "        return None\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ):\n",
    "        optimizer = self.optimizer(self.parameters())\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": self.scheduler(optimizer),\n",
    "            \"monitor\": \"train/loss\",\n",
    "            \"frequency\": 1,\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler_config,\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory ./neuralresonator/fm3vnhcd/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | CoefficientsFC    | 7.7 M \n",
      "1 | criterion | FFTLoss           | 0     \n",
      "2 | encoder   | EfficientNet      | 5.3 M \n",
      "3 | mse       | MeanSquaredError  | 0     \n",
      "4 | mae       | MeanAbsoluteError | 0     \n",
      "------------------------------------------------\n",
      "12.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.9 M    Total params\n",
      "51.785    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5b7125301b4bc2927ce08b41820a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed4f98ac60743b1a58c3f7e70c2100b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310bfe3c78284fcb8ba2d43447ca8d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "from neuralresonator.data import MultiShapeMultiMaterialDataModule\n",
    "from neuralresonator.models import FC\n",
    "from dataclasses import dataclass\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "dataset_args = dict()\n",
    "\n",
    "datamodule = MultiShapeMultiMaterialDataModule(\n",
    "    train_index_map_path=\"data/index_map.csv\",\n",
    "    val_index_map_path=\"data/index_map.csv\",\n",
    "    test_index_map_path=\"data/index_map.csv\",\n",
    ")\n",
    "\n",
    "cfg = OmegaConf.create(\n",
    "    {\n",
    "        \"_target_\": \"neuralresonator.training.MultiShapeMultiMaterialLitModule\",\n",
    "        \"model\": {\n",
    "            \"_target_\": \"neuralresonator.models.CoefficientsFC\",\n",
    "            \"input_size\": 1007,\n",
    "            \"hidden_sizes\": [1024, 1024, 1024, 1024, 1024, 1024],\n",
    "            \"n_parallel\": 32,\n",
    "            \"n_biquads\": 2,\n",
    "        },\n",
    "\n",
    "        \"criterion\": {\n",
    "            \"_target_\": \"neuralresonator.utilities.FFTLoss\",\n",
    "        },\n",
    "        \"optimizer\": {\n",
    "            \"_target_\": \"torch.optim.Adam\",\n",
    "            \"_partial_\": True,\n",
    "            \"lr\": 0.0001,\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"_target_\": \"torch.optim.lr_scheduler.ExponentialLR\",\n",
    "            \"_partial_\": True,\n",
    "            \"gamma\": 0.999,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "from lightning.pytorch import loggers\n",
    "\n",
    "model = instantiate(cfg)\n",
    "logger = loggers.WandbLogger(project=\"neuralresonator\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=1,\n",
    "    max_epochs=1,\n",
    "    limit_val_batches=1,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hparams: \"criterion\": FFTLoss()\n",
      "\"model\":     CoefficientsFC(\n",
      "  (fc): FC(\n",
      "    (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (network): Sequential(\n",
      "      (0): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1007, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (1): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (2): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (3): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (4): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (5): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (6): FCBlock(\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (ln): Identity()\n",
      "      )\n",
      "      (7): Linear(in_features=1024, out_features=320, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\"optimizer\": functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0001)\n",
      "\"scheduler\": functools.partial(<class 'torch.optim.lr_scheduler.ExponentialLR'>, gamma=0.999, verbose=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n",
      "/home/diaz/anaconda3/envs/modal/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "# Checkpointing\n",
    "print(f\"Model hparams: {model.hparams}\")\n",
    "trainer.save_checkpoint(\"checkpoint.ckpt\")\n",
    "\n",
    "# Load checkpoint\n",
    "model = MultiShapeMultiMaterialLitModule.load_from_checkpoint(\"checkpoint.ckpt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
