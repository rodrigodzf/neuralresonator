{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts\n",
    "\n",
    "> Scripts for training and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "import lightning as pl\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from lightning.pytorch.utilities import rank_zero_only\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from neuralresonator.data import generate_random_dataset\n",
    "from neuralresonator.training import MultiShapeMultiMaterialLitModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@rank_zero_only\n",
    "def log_hyperparameters(\n",
    "    object_dict: dict,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log hyperparameters to all loggers.\n",
    "    \"\"\"\n",
    "\n",
    "    hparams = {}\n",
    "    cfg = object_dict[\"cfg\"]\n",
    "    model = object_dict[\"model\"]\n",
    "    trainer = object_dict[\"trainer\"]\n",
    "\n",
    "    hparams[\"model\"] = cfg[\"model\"]\n",
    "\n",
    "    # save number of model parameters\n",
    "    hparams[\"model/params/total\"] = sum(p.numel() for p in model.parameters())\n",
    "    hparams[\"model/params/trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad\n",
    "    )\n",
    "    hparams[\"model/params/non_trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if not p.requires_grad\n",
    "    )\n",
    "\n",
    "    hparams[\"datamodule\"] = cfg[\"datamodule\"]\n",
    "    hparams[\"trainer\"] = cfg[\"trainer\"]\n",
    "\n",
    "    # send hparams to all loggers\n",
    "    trainer.logger.log_hyperparams(hparams)\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"train\")\n",
    "def train(\n",
    "    cfg: DictConfig,\n",
    "):\n",
    "    if cfg.get(\"seed\"):\n",
    "        pl.seed_everything(cfg.seed, workers=True)\n",
    "\n",
    "    datamodule = hydra.utils.instantiate(cfg.datamodule)\n",
    "    model = hydra.utils.instantiate(cfg.model)\n",
    "    logger = hydra.utils.instantiate(cfg.logger)\n",
    "    trainer = hydra.utils.instantiate(cfg.trainer, logger=logger)\n",
    "\n",
    "    object_dict = {\n",
    "        \"cfg\": cfg,\n",
    "        \"datamodule\": datamodule,\n",
    "        \"model\": model,\n",
    "        \"logger\": logger,\n",
    "        \"trainer\": trainer,\n",
    "    }\n",
    "\n",
    "    if logger:\n",
    "        log_hyperparameters(object_dict)\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule, ckpt_path=cfg.get(\"ckpt_path\"))\n",
    "    trainer.test(model, datamodule=datamodule, ckpt_path=cfg.get(\"ckpt_path\"))\n",
    "\n",
    "    # print total number of batches, batch size and number of samples\n",
    "    print(f\"Total number of batches: {len(datamodule.test_dataloader())}\")\n",
    "    print(f\"Batch size: {cfg.datamodule.batch_size}\")\n",
    "    print(\n",
    "        \"Number of samples:\"\n",
    "        f\" {len(datamodule.test_dataloader()) * cfg.datamodule.batch_size}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = 3\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"train.yaml\",\n",
    "        return_hydra_config=True,\n",
    "        overrides=[\n",
    "            \"trainer.max_epochs=1\",\n",
    "            \"hydra.runtime.output_dir=outputs\",\n",
    "            \"paths.output_dir=${hydra.runtime.output_dir}\",\n",
    "            \"paths.work_dir=${hydra.runtime.cwd}\",\n",
    "            \"seed=42\",\n",
    "            \"logger=null\",\n",
    "            \"++datamodule.train_index_map_path=data/index_map.csv\",\n",
    "            \"++datamodule.val_index_map_path=data/index_map.csv\",\n",
    "            \"++datamodule.test_index_map_path=data/index_map.csv\",\n",
    "        ],\n",
    "    )\n",
    "    train(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"generate_dataset\")\n",
    "def gen_dataset(\n",
    "    cfg: DictConfig,\n",
    "):\n",
    "    if cfg.get(\"seed\"):\n",
    "        pl.seed_everything(cfg.seed, workers=True)\n",
    "\n",
    "    paths: dict = {key: Path(val) for key, val in cfg.paths.items()}\n",
    "    \n",
    "    if not paths['train_data_dir'].exists():\n",
    "        paths['train_data_dir'].mkdir(parents=True)\n",
    "    if not paths['val_data_dir'].exists():\n",
    "        paths['val_data_dir'].mkdir(parents=True)\n",
    "    if not paths['test_data_dir'].exists():\n",
    "        paths['test_data_dir'].mkdir(parents=True)\n",
    "\n",
    "    print(\"Generating training data...\")\n",
    "    generate_random_dataset(\n",
    "        n_modes=cfg.n_modes,\n",
    "        n_vertices=cfg.n_vertices,\n",
    "        n_refinements=cfg.n_refinements,\n",
    "        data_dir=paths['train_data_dir'],\n",
    "        n_shapes=cfg.n_train_shapes,\n",
    "        n_materials=cfg.n_train_materials,\n",
    "        materials=cfg.train_materials,\n",
    "    )\n",
    "    \n",
    "    print(\"Generating validation data...\")\n",
    "    generate_random_dataset(\n",
    "        n_modes=cfg.n_modes,\n",
    "        n_vertices=cfg.n_vertices,\n",
    "        n_refinements=cfg.n_refinements,\n",
    "        data_dir=paths['val_data_dir'],\n",
    "        n_shapes=cfg.n_val_shapes,\n",
    "        n_materials=cfg.n_val_materials,\n",
    "        materials=cfg.val_materials,\n",
    "    )\n",
    "\n",
    "    print(\"Generating test data...\")\n",
    "    generate_random_dataset(\n",
    "        n_modes=cfg.n_modes,\n",
    "        n_vertices=cfg.n_vertices,\n",
    "        n_refinements=cfg.n_refinements,\n",
    "        data_dir=paths['test_data_dir'],\n",
    "        n_shapes=cfg.n_test_shapes,\n",
    "        n_materials=cfg.n_test_materials,\n",
    "        materials=cfg.test_materials,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"export\")\n",
    "def export(\n",
    "    cfg: DictConfig,\n",
    "):\n",
    "\n",
    "    # Load checkpoint\n",
    "    model = MultiShapeMultiMaterialLitModule.load_from_checkpoint(cfg.ckpt_path)\n",
    "    model.eval()\n",
    "\n",
    "    # export encoder to torchscript\n",
    "    script = torch.jit.script(model.encoder)\n",
    "    torch.jit.save(script, cfg.encoder_path)\n",
    "\n",
    "    # export coefficient model to torchscript\n",
    "    script = torch.jit.script(model.model)\n",
    "    torch.jit.save(script, cfg.coefficient_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
